{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducting Dataset to Upload to Github\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\anaya\\OneDrive\\Desktop\\Anay Masters\\Intro to NLP\\NLP_Group_7\\ReducedDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139419</td>\n",
       "      <td>/foo-fighters/</td>\n",
       "      <td>Hey, Johnny Park!</td>\n",
       "      <td>/foo-fighters/hey-johnny-park.html</td>\n",
       "      <td>Come and I'll take you under\\r\\nThis beautiful...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290738</td>\n",
       "      <td>/mxpx/</td>\n",
       "      <td>Call In Sick</td>\n",
       "      <td>/mxpx/call-in-sick.html</td>\n",
       "      <td>Oh how I missed you,\\r\\nOh how I needed you to...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162905</td>\n",
       "      <td>/arch-enemy/</td>\n",
       "      <td>Despicable Heroes</td>\n",
       "      <td>/arch-enemy/despicable-heroes.html</td>\n",
       "      <td>I spit in your face, preacers and leaders\\r\\nS...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281035</td>\n",
       "      <td>/the-maine/</td>\n",
       "      <td>Whoever She Is</td>\n",
       "      <td>/the-maine/whoever-she-is.html</td>\n",
       "      <td>I thought I had my girl but she ran away\\r\\nMy...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>253213</td>\n",
       "      <td>/a-ha/</td>\n",
       "      <td>Days On End</td>\n",
       "      <td>/a-ha/days-on-end.html</td>\n",
       "      <td>Do know why winter's such a cold and lonely pl...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           ALink              SName  \\\n",
       "0      139419  /foo-fighters/  Hey, Johnny Park!   \n",
       "1      290738          /mxpx/       Call In Sick   \n",
       "2      162905    /arch-enemy/  Despicable Heroes   \n",
       "3      281035     /the-maine/     Whoever She Is   \n",
       "4      253213          /a-ha/        Days On End   \n",
       "\n",
       "                                SLink  \\\n",
       "0  /foo-fighters/hey-johnny-park.html   \n",
       "1             /mxpx/call-in-sick.html   \n",
       "2  /arch-enemy/despicable-heroes.html   \n",
       "3      /the-maine/whoever-she-is.html   \n",
       "4              /a-ha/days-on-end.html   \n",
       "\n",
       "                                               Lyric language  \n",
       "0  Come and I'll take you under\\r\\nThis beautiful...       en  \n",
       "1  Oh how I missed you,\\r\\nOh how I needed you to...       en  \n",
       "2  I spit in your face, preacers and leaders\\r\\nS...       en  \n",
       "3  I thought I had my girl but she ran away\\r\\nMy...       en  \n",
       "4  Do know why winter's such a cold and lonely pl...       en  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Download the stopwords library\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Establish a word punctuation tokenizer\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "\n",
    "# Establish the English stop words\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # Lowercase and remove special characters and whitespaces\n",
    "    doc = re.sub(r\"[^a-zA-Z\\s']\", '', doc, re.I | re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "\n",
    "\n",
    "    # Tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words and not token.isdigit()]\n",
    "    # Re-create the document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "\n",
    "    doc = re.sub(r\"'\\s*\", \"\", doc)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "norm_corpus = normalize_corpus(df['Lyric'])\n",
    "lemmatized_corpus = []\n",
    "\n",
    "for text in norm_corpus[0:df.shape[0]]:\n",
    "    doc = nlp(text.item())  \n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "    lemmatized_corpus.append(lemmatized_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "      <th>Lemmatized_Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139419</td>\n",
       "      <td>/foo-fighters/</td>\n",
       "      <td>Hey, Johnny Park!</td>\n",
       "      <td>/foo-fighters/hey-johnny-park.html</td>\n",
       "      <td>Come and I'll take you under\\r\\nThis beautiful...</td>\n",
       "      <td>en</td>\n",
       "      <td>come take beautiful bruise color everything fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290738</td>\n",
       "      <td>/mxpx/</td>\n",
       "      <td>Call In Sick</td>\n",
       "      <td>/mxpx/call-in-sick.html</td>\n",
       "      <td>Oh how I missed you,\\r\\nOh how I needed you to...</td>\n",
       "      <td>en</td>\n",
       "      <td>oh miss oh need today oh miss oh need today ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162905</td>\n",
       "      <td>/arch-enemy/</td>\n",
       "      <td>Despicable Heroes</td>\n",
       "      <td>/arch-enemy/despicable-heroes.html</td>\n",
       "      <td>I spit in your face, preacers and leaders\\r\\nS...</td>\n",
       "      <td>en</td>\n",
       "      <td>spit face preacer leader spew false dogma beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281035</td>\n",
       "      <td>/the-maine/</td>\n",
       "      <td>Whoever She Is</td>\n",
       "      <td>/the-maine/whoever-she-is.html</td>\n",
       "      <td>I thought I had my girl but she ran away\\r\\nMy...</td>\n",
       "      <td>en</td>\n",
       "      <td>think girl run away car got steal go to late w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>253213</td>\n",
       "      <td>/a-ha/</td>\n",
       "      <td>Days On End</td>\n",
       "      <td>/a-ha/days-on-end.html</td>\n",
       "      <td>Do know why winter's such a cold and lonely pl...</td>\n",
       "      <td>en</td>\n",
       "      <td>know winter cold lonely place breath bleach fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           ALink              SName  \\\n",
       "0      139419  /foo-fighters/  Hey, Johnny Park!   \n",
       "1      290738          /mxpx/       Call In Sick   \n",
       "2      162905    /arch-enemy/  Despicable Heroes   \n",
       "3      281035     /the-maine/     Whoever She Is   \n",
       "4      253213          /a-ha/        Days On End   \n",
       "\n",
       "                                SLink  \\\n",
       "0  /foo-fighters/hey-johnny-park.html   \n",
       "1             /mxpx/call-in-sick.html   \n",
       "2  /arch-enemy/despicable-heroes.html   \n",
       "3      /the-maine/whoever-she-is.html   \n",
       "4              /a-ha/days-on-end.html   \n",
       "\n",
       "                                               Lyric language  \\\n",
       "0  Come and I'll take you under\\r\\nThis beautiful...       en   \n",
       "1  Oh how I missed you,\\r\\nOh how I needed you to...       en   \n",
       "2  I spit in your face, preacers and leaders\\r\\nS...       en   \n",
       "3  I thought I had my girl but she ran away\\r\\nMy...       en   \n",
       "4  Do know why winter's such a cold and lonely pl...       en   \n",
       "\n",
       "                                   Lemmatized_Lyrics  \n",
       "0  come take beautiful bruise color everything fa...  \n",
       "1  oh miss oh need today oh miss oh need today ca...  \n",
       "2  spit face preacer leader spew false dogma beli...  \n",
       "3  think girl run away car got steal go to late w...  \n",
       "4  know winter cold lonely place breath bleach fa...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Lemmatized_Lyrics'] = lemmatized_corpus\n",
    "df.to_csv(r'C:\\Users\\anaya\\OneDrive\\Desktop\\Anay Masters\\Intro to NLP\\NLP_Group_7\\LemmatizedDataset.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anaya\\OneDrive\\Desktop\\Anay Masters\\Intro to NLP\\NLP_Group_7\\MeloMatch\\Reduce_Dataset.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/anaya/OneDrive/Desktop/Anay%20Masters/Intro%20to%20NLP/NLP_Group_7/MeloMatch/Reduce_Dataset.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mvader_lexicon\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anaya/OneDrive/Desktop/Anay%20Masters/Intro%20to%20NLP/NLP_Group_7/MeloMatch/Reduce_Dataset.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m analyzer \u001b[39m=\u001b[39m SentimentIntensityAnalyzer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anaya/OneDrive/Desktop/Anay%20Masters/Intro%20to%20NLP/NLP_Group_7/MeloMatch/Reduce_Dataset.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_sentiment_score\u001b[39m(lyrics):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('vader_lexicon')\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_score(lyrics):\n",
    "    sentiment = analyzer.polarity_scores(lyrics)\n",
    "    pos_sentiment = sentiment['pos']\n",
    "    neu_sentiment = sentiment['neu']\n",
    "    neg_sentiment = sentiment['neg']\n",
    "    if pos_sentiment > neg_sentiment and pos_sentiment > neg_sentiment:\n",
    "        sentiment_score = 'pos'\n",
    "    elif neu_sentiment > pos_sentiment and neu_sentiment > neg_sentiment:\n",
    "        sentiment_score = 'neu'\n",
    "    elif neg_sentiment > pos_sentiment and neg_sentiment > neu_sentiment:\n",
    "        sentiment_score = 'neg'\n",
    "    return sentiment_score\n",
    "\n",
    "lemmatized_lyrics_list = df['Lemmatized_Lyrics'].tolist()\n",
    "print(lemmatized_lyrics_list)\n",
    "print('hi')\n",
    "sentiment_scorelist = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     sentiment_score = get_sentiment_score(lemmatized_lyrics_list[i])\n",
    "#     sentiment_scorelist.append(sentiment_score)\n",
    "# df['Sentiment'] = sentiment_scorelist\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
