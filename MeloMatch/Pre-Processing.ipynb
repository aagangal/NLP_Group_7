{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7fb8b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from gensim.matutils import hellinger\n",
    "from scipy.spatial.distance import cosine\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573ac7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f78c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\trevo\\NLP\\data\\lyrics-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e03e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Arerê</td>\n",
       "      <td>/ivete-sangalo/arere.html</td>\n",
       "      <td>Tudo o que eu quero nessa vida,\\nToda vida, é\\...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Se Eu Não Te Amasse Tanto Assim</td>\n",
       "      <td>/ivete-sangalo/se-eu-nao-te-amasse-tanto-assim...</td>\n",
       "      <td>Meu coração\\nSem direção\\nVoando só por voar\\n...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Céu da Boca</td>\n",
       "      <td>/ivete-sangalo/chupa-toda.html</td>\n",
       "      <td>É de babaixá!\\nÉ de balacubaca!\\nÉ de babaixá!...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Quando A Chuva Passar</td>\n",
       "      <td>/ivete-sangalo/quando-a-chuva-passar.html</td>\n",
       "      <td>Quando a chuva passar\\n\\nPra quê falar\\nSe voc...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Sorte Grande</td>\n",
       "      <td>/ivete-sangalo/sorte-grande.html</td>\n",
       "      <td>A minha sorte grande foi você cair do céu\\nMin...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ALink                            SName  \\\n",
       "0  /ivete-sangalo/                            Arerê   \n",
       "1  /ivete-sangalo/  Se Eu Não Te Amasse Tanto Assim   \n",
       "2  /ivete-sangalo/                      Céu da Boca   \n",
       "3  /ivete-sangalo/            Quando A Chuva Passar   \n",
       "4  /ivete-sangalo/                     Sorte Grande   \n",
       "\n",
       "                                               SLink  \\\n",
       "0                          /ivete-sangalo/arere.html   \n",
       "1  /ivete-sangalo/se-eu-nao-te-amasse-tanto-assim...   \n",
       "2                     /ivete-sangalo/chupa-toda.html   \n",
       "3          /ivete-sangalo/quando-a-chuva-passar.html   \n",
       "4                   /ivete-sangalo/sorte-grande.html   \n",
       "\n",
       "                                               Lyric language  \n",
       "0  Tudo o que eu quero nessa vida,\\nToda vida, é\\...       pt  \n",
       "1  Meu coração\\nSem direção\\nVoando só por voar\\n...       pt  \n",
       "2  É de babaixá!\\nÉ de balacubaca!\\nÉ de babaixá!...       pt  \n",
       "3  Quando a chuva passar\\n\\nPra quê falar\\nSe voc...       pt  \n",
       "4  A minha sorte grande foi você cair do céu\\nMin...       pt  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab431bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df[df['language']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d078b138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>/ivete-sangalo/careless-whisper.html</td>\n",
       "      <td>I feel so unsure\\nAs I take your hand and lead...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Could You Be Loved / Citação Musical do Rap: S...</td>\n",
       "      <td>/ivete-sangalo/could-you-be-loved-citacao-musi...</td>\n",
       "      <td>Don't let them fool, ya\\nOr even try to school...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Cruisin' (Part. Saulo)</td>\n",
       "      <td>/ivete-sangalo/cruisin-part-saulo.html</td>\n",
       "      <td>Baby, let's cruise, away from here\\nDon't be c...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>Easy</td>\n",
       "      <td>/ivete-sangalo/easy.html</td>\n",
       "      <td>Know it sounds funny\\nBut, I just can't stand ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>/ivete-sangalo/</td>\n",
       "      <td>For Your Babies (The Voice cover)</td>\n",
       "      <td>/ivete-sangalo/for-your-babies-the-voice-cover...</td>\n",
       "      <td>You've got that look again\\nThe one I hoped I ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ALink                                              SName  \\\n",
       "69   /ivete-sangalo/                                   Careless Whisper   \n",
       "86   /ivete-sangalo/  Could You Be Loved / Citação Musical do Rap: S...   \n",
       "88   /ivete-sangalo/                             Cruisin' (Part. Saulo)   \n",
       "111  /ivete-sangalo/                                               Easy   \n",
       "140  /ivete-sangalo/                  For Your Babies (The Voice cover)   \n",
       "\n",
       "                                                 SLink  \\\n",
       "69                /ivete-sangalo/careless-whisper.html   \n",
       "86   /ivete-sangalo/could-you-be-loved-citacao-musi...   \n",
       "88              /ivete-sangalo/cruisin-part-saulo.html   \n",
       "111                           /ivete-sangalo/easy.html   \n",
       "140  /ivete-sangalo/for-your-babies-the-voice-cover...   \n",
       "\n",
       "                                                 Lyric language  \n",
       "69   I feel so unsure\\nAs I take your hand and lead...       en  \n",
       "86   Don't let them fool, ya\\nOr even try to school...       en  \n",
       "88   Baby, let's cruise, away from here\\nDon't be c...       en  \n",
       "111  Know it sounds funny\\nBut, I just can't stand ...       en  \n",
       "140  You've got that look again\\nThe one I hoped I ...       en  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "085e9f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191814"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74b6357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baby, let's cruise, away from here\n",
      "Don't be confused, the way is clear\n",
      "And if you want it you got it forever\n",
      "This is not a one night stand, baby\n",
      "\n",
      "Let the music take your mind\n",
      "Just release & you will find\n",
      "You're gonna fly away\n",
      "Glad you're goin' my way\n",
      "I love it when we're cruisin' together\n",
      "Music is played for love\n",
      "Cruisin' is made for love\n",
      "I love it when we're cruisin' together\n",
      "\n",
      "Baby, tonight belongs to us\n",
      "Everything's right, do what you must\n",
      "And inch by inch we get closer & closer\n",
      "\n",
      "To every little part of each other, ooh, baby, yeah, so\n",
      "\n",
      "Let the music take your mind\n",
      "Just release & you will find\n",
      "You're gonna fly away\n",
      "Glad you're going my way\n",
      "I love it when we're cruisin' together\n",
      "Music is played for love\n",
      "Cruisin' is made for love\n",
      "I love it when we're cruisin' together\n",
      "\n",
      "You're gonna fly away\n",
      "\n",
      "Cruise with me, baby\n"
     ]
    }
   ],
   "source": [
    "print(df_en['Lyric'].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ba571b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\trevo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the stopwords library\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Establish a word punctuation tokenizer\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "\n",
    "# Establish the English stop words\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # Lowercase and remove special characters and whitespaces\n",
    "    doc = re.sub(r\"[^a-zA-Z\\s']\", '', doc, re.I | re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "\n",
    "\n",
    "    # Tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words and not token.isdigit()]\n",
    "    # Re-create the document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "\n",
    "    doc = re.sub(r\"'\\s*\", \"\", doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f5ea694",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "norm_corpus = normalize_corpus(df_en['Lyric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a35cc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby let cruise away confused way clear want got forever one night stand baby let music take mind release find gonna fly away glad goin way love cruisin together music played love cruisin made love love cruisin together baby tonight belongs us everything right must inch inch get closer closer every little part ooh baby yeah let music take mind release find gonna fly away glad going way love cruisin together music played love cruisin made love love cruisin together gonna fly away cruise baby\n"
     ]
    }
   ],
   "source": [
    "print(norm_corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a046be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby baby\n",
      "let let\n",
      "cruise cruise\n",
      "away away\n",
      "confused confused\n",
      "way way\n",
      "clear clear\n",
      "want want\n",
      "got get\n",
      "forever forever\n",
      "one one\n",
      "night night\n",
      "stand stand\n",
      "baby baby\n",
      "let let\n",
      "music music\n",
      "take take\n",
      "mind mind\n",
      "release release\n",
      "find find\n",
      "gon gon\n",
      "na na\n",
      "fly fly\n",
      "away away\n",
      "glad glad\n",
      "goin goin\n",
      "way way\n",
      "love love\n",
      "cruisin cruisin\n",
      "together together\n",
      "music music\n",
      "played play\n",
      "love love\n",
      "cruisin cruisin\n",
      "made make\n",
      "love love\n",
      "love love\n",
      "cruisin cruisin\n",
      "together together\n",
      "baby baby\n",
      "tonight tonight\n",
      "belongs belong\n",
      "us we\n",
      "everything everything\n",
      "right right\n",
      "must must\n",
      "inch inch\n",
      "inch inch\n",
      "get get\n",
      "closer close\n",
      "closer close\n",
      "every every\n",
      "little little\n",
      "part part\n",
      "ooh ooh\n",
      "baby baby\n",
      "yeah yeah\n",
      "let let\n",
      "music music\n",
      "take take\n",
      "mind mind\n",
      "release release\n",
      "find find\n",
      "gon gon\n",
      "na na\n",
      "fly fly\n",
      "away away\n",
      "glad glad\n",
      "going go\n",
      "way way\n",
      "love love\n",
      "cruisin cruisin\n",
      "together together\n",
      "music music\n",
      "played play\n",
      "love love\n",
      "cruisin cruisin\n",
      "made make\n",
      "love love\n",
      "love love\n",
      "cruisin cruisin\n",
      "together together\n",
      "gon gon\n",
      "na na\n",
      "fly fly\n",
      "away away\n",
      "cruise cruise\n",
      "baby baby\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(norm_corpus[2].item())\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c25f1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_corpus = []\n",
    "\n",
    "for text in norm_corpus[0:500]:\n",
    "    doc = nlp(text.item())  \n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "    lemmatized_corpus.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ecfbc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby let cruise away confused way clear want get forever one night stand baby let music take mind release find gon na fly away glad goin way love cruisin together music play love cruisin make love love cruisin together baby tonight belong we everything right must inch inch get close close every little part ooh baby yeah let music take mind release find gon na fly away glad go way love cruisin together music play love cruisin make love love cruisin together gon na fly away cruise baby\n"
     ]
    }
   ],
   "source": [
    "print(lemmatized_corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1af1904d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.048*\"work\" + 0.047*\"like\" + 0.034*\"halo\" + 0.030*\"girl\" + 0.030*\"diamond\" + 0.025*\"run\" + 0.023*\"shine\" + 0.022*\"bright\" + 0.020*\"get\" + 0.020*\"see\"\n",
      "Topic 1: 0.022*\"diva\" + 0.022*\"think\" + 0.021*\"get\" + 0.021*\"feel\" + 0.017*\"turn\" + 0.017*\"like\" + 0.016*\"stand\" + 0.015*\"love\" + 0.015*\"make\" + 0.014*\"man\"\n",
      "Topic 2: 0.033*\"top\" + 0.026*\"get\" + 0.024*\"love\" + 0.024*\"like\" + 0.021*\"put\" + 0.019*\"right\" + 0.016*\"one\" + 0.016*\"baby\" + 0.015*\"ooh\" + 0.011*\"see\"\n",
      "Topic 3: 0.037*\"bad\" + 0.025*\"oh\" + 0.024*\"daddy\" + 0.020*\"say\" + 0.020*\"get\" + 0.019*\"one\" + 0.016*\"like\" + 0.016*\"shoot\" + 0.016*\"bum\" + 0.013*\"girl\"\n",
      "Topic 4: 0.040*\"know\" + 0.020*\"love\" + 0.019*\"get\" + 0.019*\"wait\" + 0.019*\"thing\" + 0.017*\"never\" + 0.017*\"time\" + 0.014*\"want\" + 0.014*\"think\" + 0.014*\"go\"\n",
      "Topic 5: 0.030*\"na\" + 0.026*\"love\" + 0.021*\"time\" + 0.021*\"like\" + 0.019*\"feel\" + 0.018*\"way\" + 0.018*\"get\" + 0.016*\"baby\" + 0.015*\"know\" + 0.015*\"say\"\n",
      "Topic 6: 0.097*\"oh\" + 0.048*\"get\" + 0.031*\"go\" + 0.022*\"uh\" + 0.017*\"know\" + 0.016*\"look\" + 0.013*\"crazy\" + 0.012*\"come\" + 0.012*\"right\" + 0.012*\"love\"\n",
      "Topic 7: 0.057*\"okay\" + 0.042*\"slay\" + 0.040*\"get\" + 0.020*\"good\" + 0.017*\"dream\" + 0.017*\"let\" + 0.017*\"cause\" + 0.014*\"straight\" + 0.013*\"lady\" + 0.010*\"go\"\n",
      "Topic 8: 0.025*\"see\" + 0.023*\"world\" + 0.022*\"know\" + 0.016*\"one\" + 0.014*\"fly\" + 0.014*\"ole\" + 0.013*\"light\" + 0.011*\"girl\" + 0.010*\"like\" + 0.010*\"night\"\n",
      "Topic 9: 0.023*\"say\" + 0.020*\"go\" + 0.018*\"hello\" + 0.017*\"love\" + 0.016*\"keep\" + 0.015*\"know\" + 0.015*\"one\" + 0.013*\"come\" + 0.013*\"turn\" + 0.012*\"cherry\"\n",
      "Topic 10: 0.046*\"like\" + 0.023*\"baby\" + 0.018*\"get\" + 0.016*\"let\" + 0.015*\"want\" + 0.013*\"video\" + 0.013*\"know\" + 0.011*\"say\" + 0.010*\"lady\" + 0.010*\"back\"\n",
      "Topic 11: 0.067*\"cake\" + 0.047*\"body\" + 0.029*\"get\" + 0.028*\"tonight\" + 0.025*\"wanna\" + 0.023*\"bitch\" + 0.019*\"well\" + 0.019*\"like\" + 0.017*\"blah\" + 0.016*\"bodied\"\n",
      "Topic 12: 0.097*\"love\" + 0.025*\"baby\" + 0.024*\"say\" + 0.021*\"get\" + 0.014*\"night\" + 0.013*\"want\" + 0.013*\"like\" + 0.012*\"name\" + 0.010*\"feel\" + 0.009*\"know\"\n",
      "Topic 13: 0.070*\"love\" + 0.054*\"let\" + 0.050*\"go\" + 0.019*\"baby\" + 0.016*\"take\" + 0.015*\"light\" + 0.013*\"never\" + 0.013*\"need\" + 0.011*\"like\" + 0.011*\"say\"\n",
      "Topic 14: 0.057*\"yeah\" + 0.022*\"get\" + 0.021*\"know\" + 0.018*\"oh\" + 0.015*\"baby\" + 0.015*\"cause\" + 0.014*\"girl\" + 0.013*\"make\" + 0.012*\"ya\" + 0.012*\"feel\"\n",
      "Topic 15: 0.036*\"let\" + 0.027*\"look\" + 0.019*\"beautiful\" + 0.019*\"upgrade\" + 0.017*\"baby\" + 0.013*\"start\" + 0.012*\"good\" + 0.012*\"u\" + 0.011*\"ay\" + 0.010*\"one\"\n",
      "Topic 16: 0.066*\"oh\" + 0.041*\"lose\" + 0.022*\"mind\" + 0.022*\"yo\" + 0.020*\"hey\" + 0.017*\"ya\" + 0.017*\"ring\" + 0.016*\"put\" + 0.015*\"like\" + 0.013*\"think\"\n",
      "Topic 17: 0.021*\"sorry\" + 0.018*\"pop\" + 0.016*\"catch\" + 0.014*\"bubble\" + 0.013*\"take\" + 0.012*\"boy\" + 0.012*\"bandera\" + 0.011*\"make\" + 0.011*\"hey\" + 0.011*\"go\"\n",
      "Topic 18: 0.026*\"lonely\" + 0.022*\"california\" + 0.020*\"live\" + 0.020*\"need\" + 0.016*\"come\" + 0.016*\"world\" + 0.015*\"life\" + 0.015*\"baby\" + 0.015*\"want\" + 0.013*\"bi\"\n",
      "Topic 19: 0.039*\"boom\" + 0.034*\"like\" + 0.033*\"la\" + 0.021*\"clap\" + 0.021*\"smack\" + 0.017*\"go\" + 0.016*\"eh\" + 0.015*\"side\" + 0.015*\"care\" + 0.015*\"hand\"\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = [text.split() for text in lemmatized_corpus]\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_corpus)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_corpus]\n",
    "\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=20, id2word=dictionary, passes=35, random_state = 42)\n",
    "\n",
    "for topic_id in range(20):\n",
    "    topic = lda_model.print_topic(topic_id)\n",
    "    print(f\"Topic {topic_id}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "800298a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_topic_distribution = [lda_model[doc] for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0827396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.99547607)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_topic_distribution[496]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a53207e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.9966545)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_topic_distribution[497]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9ff5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004174645345004054\n"
     ]
    }
   ],
   "source": [
    "song_0_dist = song_topic_distribution[496]\n",
    "song_1_dist = song_topic_distribution[497]\n",
    "\n",
    "hellinger_distance = hellinger(song_0_dist, song_1_dist)\n",
    "\n",
    "print(hellinger_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf22c5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel so unsure\n",
      "As I take your hand and lead you to the dance floor\n",
      "As the music dies, something in your eyes\n",
      "Calls to mind a silver screen\n",
      "And all those sad goodbyes\n",
      "\n",
      "I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste the chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Time can never mend\n",
      "The careless whispers of a good friend\n",
      "To the heart and mind\n",
      "Ignorance is kind\n",
      "There's no comfort in the truth\n",
      "Pain is all you'll find\n",
      "\n",
      "I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste this chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "Never without your love\n",
      "\n",
      "Tonight the music seems so loud\n",
      "I wish that we could lose this crowd\n",
      "Maybe it's better this way\n",
      "We'd hurt each other with the things we'd want to say\n",
      "\n",
      "We could have been so good together\n",
      "We could have lived this dance forever\n",
      "But now who's gonna dance with me?\n",
      "Please stay\n",
      "\n",
      "And I'm never gonna dance again\n",
      "Guilty feet have got no rhythm\n",
      "Though it's easy to pretend\n",
      "I know you're not a fool\n",
      "\n",
      "Should've known better than to cheat a friend\n",
      "And waste the chance that I've been given\n",
      "So I'm never gonna dance again\n",
      "The way I danced with you\n",
      "\n",
      "(Now that you're gone) Now that you're gone\n",
      "(Now that you're gone) What I did's so wrong, so wrong\n",
      "That you had to leave me alone?\n"
     ]
    }
   ],
   "source": [
    "print(df_en['Lyric'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b6f68b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't let them fool, ya\n",
      "Or even try to school, ya! Oh, no!\n",
      "We've got a mind of our own\n",
      "So go to hell if what you? re thinking is not right!\n",
      "Love would never leave us alone\n",
      "A-yin the darkness there must come out to light\n",
      "\n",
      "Could you be loved and be loved?\n",
      "Could you be loved and be loved?\n",
      "\n",
      "Don't let them change ya, oh!\n",
      "Or even rearrange ya! Oh, no!\n",
      "We've got a life to live\n",
      "They say: only, only\n",
      "Only the fittest of the fittest shall survive\n",
      "Stay alive! Oh!\n",
      "\n",
      "Could you be loved and be loved?\n",
      "Could you be loved, wo now! And be loved?\n",
      "\n",
      "Could you be\n",
      "Could you be\n",
      "Could you be loved?\n",
      "\n",
      "Say something!\n",
      "\n",
      "Se ligue na ternura\n",
      "Se ligue no amor\n",
      "Se ligue na ternura\n",
      "Se ligue na cor\n",
      "Se ligue na alegria\n",
      "Se ligue no prazer\n",
      "Se ligue, fique atento, se ligue, fique astral\n",
      "\n",
      "Could you be loved and be loved?\n"
     ]
    }
   ],
   "source": [
    "print(df_en['Lyric'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c520c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shine bright like a diamond\n",
      "(C'mon)\n",
      "Shine bright like a diamond\n",
      "(Yeah)\n",
      "\n",
      "You glisten so beautiful, priceless\n",
      "Listen to me, I need you to know\n",
      "How you can change my whole world\n",
      "New life, new love, I'm a new girl\n",
      "Guess you did what they coudn't\n",
      "Stayed when I pushed away and they wouldn't\n",
      "Said \"trust\" and I thought I shouldn't\n",
      "Carved your initials in my heart like wood and\n",
      "Now I'm floating through air\n",
      "Brightest in the whole sky, we both there\n",
      "Freedom in the universe, now is so clear\n",
      "I waited a lifetime\n",
      "Now you right here\n",
      "And I'm never gonna give it up\n",
      "Shinning like a million spot lights, live it up\n",
      "Blinding, diamonds, forever that's us\n",
      "And I can never get enough\n",
      "Yep\n",
      "\n",
      "Find light in the beautiful sea\n",
      "I choose to be happy\n",
      "You and I, you and I\n",
      "We're like diamonds in the sky\n",
      "\n",
      "You're a shooting star I see\n",
      "A vision of ecstasy\n",
      "When you hold me\n",
      "I'm alive\n",
      "We're like diamonds in the sky\n",
      "\n",
      "I knew that we'd become one right away\n",
      "Oh, right away\n",
      "At first sight I felt the energy of sun rays\n",
      "I saw the life inside your eyes\n",
      "\n",
      "So shine bright\n",
      "Tonight\n",
      "You and I\n",
      "We're beautiful like diamonds in the sky\n",
      "Eye to eye\n",
      "So alive\n",
      "We're beautiful like diamonds in the sky\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "We're beautiful like diamonds in the sky\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "We're beautiful like diamonds in the sky\n",
      "\n",
      "Palms rise to the universe\n",
      "As we, moonshine and molly\n",
      "Feel the warmth we'll never die\n",
      "We're like diamonds in the sky\n",
      "\n",
      "You're a shooting star I see\n",
      "A vision of ecstasy\n",
      "When you hold me\n",
      "I'm alive\n",
      "We're like diamonds in the sky\n",
      "\n",
      "At first sight I felt the energy of sun rays\n",
      "I saw the life inside your eyes\n",
      "\n",
      "So shine bright\n",
      "Tonight\n",
      "You and I\n",
      "We're beautiful like diamonds in the sky\n",
      "Eye to eye\n",
      "So alive\n",
      "We're beautiful like diamonds in the sky\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "We're beautiful like diamonds in the sky\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "We're beautiful like diamonds in the sky\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "\n",
      "So shine bright\n",
      "Tonight\n",
      "You and I\n",
      "We're beautiful like diamonds in the sky\n",
      "Eye to eye\n",
      "So alive\n",
      "We're beautiful like diamonds in the sky\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "\n",
      "Shine bright like a diamond\n"
     ]
    }
   ],
   "source": [
    "print(df_en['Lyric'].iloc[497])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d285129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "\n",
      "Find light in the beautiful sea\n",
      "I choose to be happy\n",
      "You and I, you and I\n",
      "We're like diamonds in the sky\n",
      "\n",
      "You're a shooting star I see\n",
      "A vision of ecstasy\n",
      "When you hold me, I'm alive\n",
      "We're like diamonds in the sky\n",
      "\n",
      "I knew that we'd become one right away\n",
      "Oh, right away\n",
      "At first sight, I felt the energy of sunrays\n",
      "I saw the life inside your eyes\n",
      "\n",
      "So shine bright, tonight, you and I\n",
      "We're beautiful, like diamonds in the sky\n",
      "Eye to eye, so alive\n",
      "We're beautiful, like diamonds in the sky\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "We're beautiful, like diamonds in the sky\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "We're beautiful, like diamonds in the sky\n",
      "\n",
      "Palms rise to the universe\n",
      "As we moonshine and molly\n",
      "Feel the warmth, we'll never die\n",
      "We're like diamonds in the sky\n",
      "\n",
      "You're a shooting star I see\n",
      "A vision of ecstasy\n",
      "When you hold me, I'm alive\n",
      "We're like diamonds in the sky\n",
      "\n",
      "At first sight, I felt the energy of sunrays\n",
      "I saw the life inside your eyes\n",
      "\n",
      "So shine bright, tonight, you and I\n",
      "We're beautiful, like diamonds in the sky\n",
      "Eye to eye, so alive\n",
      "We're beautiful, like diamonds in the sky\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "We're beautiful, like diamonds in the sky\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "We're beautiful, like diamonds in the sky\n",
      "\n",
      "So shine bright, tonight, you and I\n",
      "We're beautiful like diamonds in the sky\n",
      "Eye to eye, so alive\n",
      "We're beautiful, like diamonds in the sky\n",
      "\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n",
      "Shine bright like a diamond\n"
     ]
    }
   ],
   "source": [
    "print(df_en['Lyric'].iloc[496])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c52928e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Score for Song 1: 0.9998\n",
      "Sentiment Score for Song 2: 0.9999\n",
      "Cosine Similarity between Lyrics: 0.9865365982984073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\trevo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_score(lyrics):\n",
    "    sentiment = analyzer.polarity_scores(lyrics)\n",
    "    return sentiment['compound']\n",
    "\n",
    "sentiment1 = get_sentiment_score(lemmatized_corpus[496])\n",
    "sentiment2 = get_sentiment_score(lemmatized_corpus[497])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "lyrics_matrix = tfidf_vectorizer.fit_transform([lemmatized_corpus[496], lemmatized_corpus[497]])\n",
    "lyrics_similarity = cosine_similarity(lyrics_matrix)\n",
    "\n",
    "print(\"Sentiment Score for Song 1:\", sentiment1)\n",
    "print(\"Sentiment Score for Song 2:\", sentiment2)\n",
    "print(\"Cosine Similarity between Lyrics:\", lyrics_similarity[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b8a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "# Tokenize\n",
    "# Lowercase\n",
    "# punctuation removal\n",
    "# number removal\n",
    "# Stop word removal\n",
    "\n",
    "## Additional Preprocessing\n",
    "# Lemmatization and or stemming\n",
    "# Analysis word frequency determine if we need to remove high frequency low value words\n",
    "# Stop word removal\n",
    "\n",
    "## Data Check\n",
    "# Explore word stats\n",
    "# Everything is clean\n",
    "\n",
    "## NLP Processing\n",
    "# Sentiment Analysis\n",
    "# LDA\n",
    "# POS taging/Similarity\n",
    "\n",
    "## Front End\n",
    "# Django or Flask additions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n",
    "ANOTHER TEST\n",
    "\n",
    "\n",
    "FINAL TEST!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
